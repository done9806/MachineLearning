{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Used dataset: Social Network Ads https://www.kaggle.com/datasets/rakeshrau/social-network-ads\n",
    "\n",
    "#### Used packages:\n",
    "##### Package Versions: pandas: 2.0.2, numpy 1.25.0, matplotlib 3.7.1, missingno 0.5.2, seaborn 0.12.2\n",
    "##### Python Version: 3.11.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1:\n",
    "\n",
    "#### Business understanding:\n",
    "Suppose we are an e-commerce company that runs advertisements to target potential customers. We want to determine if there is a correlation between gender, age, estimated salary, and the users' purchasing behavior due to our ads.\n",
    "\n",
    "Our objective is to maximize the effectiveness of our ads by optimizing our budget and gaining a better understanding of our target audience. On the basis of existing data, we hope to be able to draw conclusions and thus determine whether a customer buys through our advertising or not on the basis of the characteristics mentioned.\n",
    "\n",
    "#### Dataset and attribute explanation:\n",
    "The dataset shows whether a person purchased a product because of social media advertisement based on gender, age and estimated salary.\n",
    "\n",
    "##### The dataset consists of five columns:\n",
    "##### UserID            = ID of each user\n",
    "##### Gender            = Gender of each user\n",
    "##### Age               = Age of each user\n",
    "##### EstimatedSalary   = Estimated salary of each user\n",
    "##### Purchased         = Shows if the user has purchased because of the AD (1 = Purchased; 0 = Not purchased)\n",
    "\n",
    "##### -> 'Gender', 'Age' and 'EstimatedSalary' represent the independent variables.\n",
    "##### -> 'Purchased' represents the dependent variable.\n",
    "##### -> 'User ID' is not required, as the column has no significance.\n",
    "\n",
    "##### Why I use the SVM-Algorithm:\n",
    "The objective of the SVM algorithm is to construct an optimal hyperplane that effectively separates classes within an n-dimensional space. By achieving this, we can accurately classify new data points into their respective categories in the future. The hyperplane represents the optimal decision boundary.\n",
    "\n",
    "Regarding the given dataset I want to classify if a person purchases or not based on the given attributes by using SVM. So based on these attributes we can predict whether a customer purchases or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Step: Importing libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Importing the libraries\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \u001b[38;5;66;03m#Linear algebra\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m#Data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \u001b[38;5;66;03m#For plotting\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "#Importing the libraries\n",
    "\n",
    "import numpy as np #Linear algebra\n",
    "import pandas as pd #Data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt #For plotting\n",
    "import missingno as msno #For missing values analysis\n",
    "import seaborn as sns #For plotting\n",
    "from matplotlib.colors import ListedColormap #For plotting\n",
    "from sklearn.model_selection import train_test_split #For splitting data into train/test\n",
    "from sklearn.preprocessing import StandardScaler #For feature scaling\n",
    "from matplotlib.colors import ListedColormap #For plotting \n",
    "from sklearn.svm import SVC #For SVM classification, imported from sklearn library\n",
    "from sklearn.metrics import confusion_matrix #For confusion matrix \n",
    "#from imblearn.over_sampling import SMOTE #For oversampling data\n",
    "from sklearn.metrics import classification_report #For classification report\n",
    "from sklearn.model_selection import GridSearchCV #For grid search cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Step: Import dataset and first examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSocial_Network_Ads.csv\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#Loading the dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Dataset can be found at: https://www.kaggle.com/datasets/rakeshrau/social-network-ads\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Social_Network_Ads.csv') #Loading the dataset\n",
    "# Dataset can be found at: https://www.kaggle.com/datasets/rakeshrau/social-network-ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() #Checking the first 5 rows of the dataset to get an idea of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail() #Checking the last 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Checking the number of rows and columns\n",
    "print(\"Number of rows is = \", df.shape[0], \" \\nNumber of columns is = \" , df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info #Checking the overall information of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes #Checking the data types of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -> All columns numerical (=Integer), except 'Gender' (=Object)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() #Checking the statistical summary of the dataset for outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -> No outliers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for missing values\n",
    "\n",
    "print(df.isnull().sum()) #Sum of missing values in each column\n",
    "\n",
    "msno.matrix(df) #Missing values show up as white lines in the plot\n",
    "plt.title('Missing Data Matrix') #Title of the plot\n",
    "plt.show() #Displaying the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -> No missing values in the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for duplicate rows\n",
    "\n",
    "df.duplicated().sum() #Sum of duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -> No duplicates in the dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all the dataset consists of 400 rows and 5 columns. 'User ID', 'Age', Estimated Salary' and 'Purchased' are numerical columns. Only 'Gender' is an object-type which needs further checking later on (Step 5: Data preprocessing) becasue object-type values often cause problems when used in ML algorithms. Also the dataset doesn't have any missing values and even no duplicates. No modifications needed at that stage, the dataset itself is in a good status and nearly ready to bes processed. Like mentioned before, only the 'Gender' column could become a problem. If there were a lot of missing values or duplicates, cleaning would be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Step: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting how many people purchased and how many didn't\n",
    "\n",
    "df['Purchased'].value_counts() #Count values in column 'Purchased'\n",
    "\n",
    "sns.set(style=\"darkgrid\")  # Set the plot style to darkgrid \n",
    "\n",
    "sns.countplot(x='Purchased', data=df) #Plotting the count of Purchased\n",
    "plt.title(\"Count of Purchased\") #Title of the plot\n",
    "plt.xlabel(\"Purchased\") #X-axis label\n",
    "plt.ylabel(\"Count\") #Y-axis label\n",
    "plt.show() #Displaying the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
